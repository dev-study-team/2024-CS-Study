![Pasted image 20240119050407](https://github.com/dev-study-team/2024-CS-Study/assets/53209324/20151e8a-d0b5-4133-91f3-e1e436f25d14)

## 로드 밸런싱 이란?

로드 밸런싱이란 말 그대로 서버가 처리해야 할 업무 혹은 요청(Load)을 여러 대의 서버로 나누어(Balancing) 처리하는 것을 의미한다. 한 대의 서버로 부하가 집중되지 않도록 트래픽을 관리해 각각의 서버가 최적의 퍼포먼스를 보일 수 있도록 하는 것이 목적이다.
보통 부하 분산이라고도 부릅니다.

## 로드 밸런싱이 왜 나오게 되었나요?

서비스의 규모가 커지고, 이용자 수가 늘어나게 되면 기존의 서버만으로는 원활한 서비스 동작이 불가능하게 되고, 이에 대처할 수 있는 방법은 크게 두 가지로 나뉩니다.

- 기존의 서버 성능을 확장하는 Scale-up 방식
- 기존의 서버와 동일하거나 낮은 성능의 서버를 증설하는 Scale-out 방식

이때 Scale-out 방식을 통해 증가한 트래픽에 대처하기로 했다면, 여러 대의 서버로 트래픽을 균등하게 분산해주는 로드 밸런싱이 반드시 필요합니다.
![[Pasted image 20240119053005.png]]

## 로드 밸런싱에 주요 기능은 어떤게 있을까요?
로드 밸런서는 다음 기능을 수행합니다.
- 여러 서버에 걸쳐 클라이언트 요청이나 네트워크 로드를 효율적으로 분산합니다.
- 온라인 상태인 서버에만 요청을 보내 고가용성과 안정성을 보장합니다. (가용성이란 사용 가능한 정도)
- 수요에 따라 서버를 추가하거나 뺄 수 있는 유연성 제공
>자동 스케일링(Auto Scaling):
  트래픽 양에 따라 서버 인스턴스의 수를 동적으로 조절하여 부하를 분산하는 방식입니다. 클라우드 환경에서 자주 사용되며, 서버 수를 증가 또는 감소시켜 실시간으로 대응할 수 있습니다

## 로드밸런싱의 이점

#### 1) 애플리케이션 가용성

서버 장애 또는 유지 관리로 인해 애플리케이션 가동 중지 시간이 늘어 방문자가 애플리케이션을 사용할 수 없게 될 수 있습니다. 로드 밸런서는 서버 문제를 자동으로 감지하고 클라이언트 트래픽을 사용 가능한 서버로 리다이렉션하여 시스템의 내결함성을 높입니다. 로드 밸런싱을 사용하여 다음 태스크를 더 쉽게 수행할 수 있습니다.

- 애플리케이션 가동 중지 없이 애플리케이션 서버 유지 관리 또는 업그레이드 실행
- 백업 사이트에 자동 재해 복구 제공
- 상태 확인을 수행하고 가동 중지를 유발할 수 있는 문제 방지

> 서버 그룹의 동적 구성
> 빠르게 변화하는 많은 애플리케이션에는 지속적으로 새 서버를 추가하거나 제거해야 합니다.   이를 통해 사용자는 실제로 사용하는 컴퓨팅 용량에 대해서만 비용을 지불하는 동시에 응답 트래픽 급증에 따라 용량을 확장할 수 있습니다. 이러한 환경에서는 로드 밸런서가 기존 연결을 중단하지 않고 그룹에서 서버를 동적으로 추가하거나 제거할 수 있다면 큰 도움이 됩니다.    

#### 2) 애플리케이션 확장성

로드 밸런서를 사용하여 여러 서버 간에 네트워크 트래픽을 지능적으로 전달할 수 있습니다. 로드 밸런싱이 다음을 수행하므로 애플리케이션에서 수천 개의 클라이언트 요청을 처리할 수 있습니다.

- 한 서버에서 트래픽 병목 현상 방지
    
- 필요한 경우 다른 서버를 추가하거나 제거할 수 있도록 애플리케이션 트래픽을 예측합니다.
    
- 안심하고 조정할 수 있도록 시스템에 중복성을 추가합니다.
    

#### 3) 애플리케이션 보안

로드 밸런서에는 인터넷 애플리케이션에 또 다른 보안 계층을 추가할 수 있는 보안 기능이 내장되어 있습니다. 이는 공격자가 서버 장애를 일으키는 수백만 개의 동시 요청으로 애플리케이션 서버를 가득 채우는 분산 서비스 거부 공격을 처리하는 데 유용한 도구입니다. 로드 밸런서는 다음을 수행할 수도 있습니다.

- 트래픽 모니터링 및 악성 콘텐츠 차단
    
- 공격 트래픽을 여러 백엔드 서버로 자동으로 리다이렉션하여 영향 최소화
    
- 추가 보안을 위해 네트워크 방화벽 그룹을 통해 트래픽 라우팅
    

#### 4) 애플리케이션 성능

로드 밸런서는 응답 시간을 늘리고 네트워크 지연 시간을 줄여 애플리케이션 성능을 향상시킵니다. 다음과 같은 몇 가지 중요한 태스크를 수행합니다.

- 서버 간에 로드를 균등하게 배포하여 애플리케이션 성능 향상
    
- 클라이언트 요청을 지리적으로 더 가까운 서버로 리다이렉션하여 지연 시간 단축
    
- 물리적 및 가상 컴퓨팅 리소스의 신뢰성 및 성능 보장


## 로드 밸런서 유형으로 무엇이 있나요? (1)

로드 밸런서는 하드웨어 로드 밸런서와 소프트웨어 로드 밸런서의 2가지 유형이 있습니다.
### 하드웨어 로드 밸런서

1. **구현 위치:** 하드웨어 로드 밸런서는 주로 네트워크 레이어에서 동작하며, 전용 장비나 하드웨어 모듈 형태로 존재합니다.
    
2. **성능:** 하드웨어 로드 밸런서는 빠른 속도와 고성능을 제공하는데, 이는 전용 하드웨어를 사용하기 때문입니다. 대규모 트래픽이나 요청을 처리하는 데 특히 효과적입니다.
    
3. **확장성:** 하드웨어 로드 밸런서는 대규모 환경에서 높은 확장성을 제공할 수 있습니다.
    
4. **물리적 요구 사항:** 하드웨어 로드 밸런서는 물리적 장치를 필요로 하며, 데이터 센터나 서버 룸에 설치됩니다.

### 소프트웨어 로드 밸런서

1. **구현 위치:** 소프트웨어 로드 밸런서는 일반적으로 애플리케이션 레이어에서 동작합니다. 이는 애플리케이션 코드 내부에서 로드 밸런싱 로직을 수행하거나, 별도의 소프트웨어 구성 요소를 통해 이루어질 수 있습니다.
    
2. **유연성:** 소프트웨어 로드 밸런서는 상대적으로 더 유연하며, 애플리케이션 코드의 수정 없이도 로드 밸런싱 기능을 도입할 수 있습니다.
    
3. **비용:** 소프트웨어 로드 밸런서는 일반적으로 하드웨어 로드 밸런서에 비해 비용이 낮을 수 있습니다. 그러나 고성능이 필요한 대규모 환경에서는 하드웨어 로드 밸런서보다는 성능 제약이 있을 수 있습니다.

### 하드웨어 로드 밸런서와 소프트웨어 로드 밸런서 비교

하드웨어 로드 밸런서는 초기 투자, 구성 및 지속적인 유지 관리가 필요합니다. 또한 최대 용량으로 하드웨어 로드 밸런서를 사용하지 않을 수도 있습니다. 특히 피크 시간 트래픽 급증을 처리하는 용도로만 하드웨어 로드 밸런서를 구매하는 경우 더욱 그렇습니다. 트래픽 볼륨이 현재 용량을 초과하여 급증하면 다른 로드 밸런서를 구매하여 설정할 수 있을 때까지 사용자에게 영향이 있습니다.

반대로 소프트웨어 기반 로드 밸런서는 훨씬 더 유연합니다. 쉽게 스케일 업하거나 스케일 다운할 수 있으며 최신 클라우드 컴퓨팅 환경과 더 잘 호환됩니다. 또한 시간이 지남에 따라 설정, 관리 및 사용하는 데 드는 비용도 줄어듭니다.

일반적으로, 중소규모 환경에서는 소프트웨어 로드 밸런서가 더 유용하며, 대규모 및 높은 성능이 필요한 환경에서는 하드웨어 로드 밸런서가 선호될 수 있습니다. 종종 두 유형을 혼합하여 사용하는 경우도 있습니다.

## 로드 밸런서  유형으로 무엇이 있나요? (2)

### 1. ALB(Application Load Balancer)

ALB는 보통 L7 로드밸런서라고도 부르는데요. L7 로드 밸런서는 애플리케이션 계층(HTTP, FTP, SMTP)에서 로드를 분산하기 때문에 HTTP 헤더, 쿠키 등과 같은 사용자의 요청을 기준으로 특정 서버에 트래픽을 분산하는 것이 가능합니다. 쉽게 말해 패킷의 내용을 확인하고 그 내용에 따라 로드를 특정 서버에 분배하는 것이 가능한 것입니다. URL에 따라 부하를 분산시키거나, HTTP 헤더의 쿠키 값에 따라 부하를 분산하는 등 클라이언트의 요청을 보다 세분화해 서버에 전달할 수 있습니다.

또한 L7 로드 밸런서의 경우 특정한 패턴을 지닌 바이러스를 감지해 네트워크를 보호할 수 있으며, DoS/DDoS와 같은 비정상적인 트래픽을 필터링할 수 있어 네트워크 보안 분야에서도 활용되고 있습니다.

L7 로드 밸런싱은 애플리케이션 특성에 민감하게 대응하여 효과적으로 트래픽을 관리할 수 있습니다. 기술적으로 L7 로드 밸런서는 L4 로드 밸런서의 기능을 포함하면서, 추가적으로 애플리케이션 레이어에서 작동하는 특수 기능을 제공합니다.
L7 로드 밸런싱은 특정 애플리케이션의 특성을 고려하여 더 미세한 수준의 로드 밸런싱을 수행할 수 있습니다.

> **캐싱(Caching):** L7 로드 밸런서는 동적 및 정적 콘텐츠에 대한 캐싱을 지원할 수 있어, 서버 부하를 줄이고 응답 속도를 향상시킬 수 있습니다. 일반적으로 캐싱은 주로 HTTP 기반의 프로토콜에서 사용됩니다. HTTP 캐싱은 웹 브라우저와 웹 서버 간의 트래픽을 줄이고 웹 페이지 로딩 속도를 향상시키는 데 도움이 됩니다.
### 2. NLB(Network Load Balancer)

L4 로드 밸런서는 네트워크 계층(IP, IPX)이나 전송 계층(TCP, UDP)의 정보(IP주소, 포트번호, MAC주소, 전송 프로토콜)를 바탕으로 로드를 분산한다.

Network Load Balancer는 IP 주소 및 기타 네트워크 정보를 검사하여 트래픽을 최적으로 리다이렉션합니다. 애플리케이션 트래픽의 소스를 추적하고 여러 서버에 고정 IP 주소를 할당할 수 있습니다. Network Load Balancer는 정적 및 동적 로드 밸런싱 알고리즘을 사용하여 서버 로드를 배포합니다.

NLB는 고성능을 요구하는 환경에서 부하분산에 적합한 솔루션입니다. 낮은 레이턴시로 초당 수백만 건의 요청을 처리할 수 있으며 갑작스러운 트래픽 증대 및 변화에도 최적화되어 있습니다. 예를 들어 지적이고 최적화된 연결을 유지하는 것이 중요한 실시간 스트리밍 서비스, 화상 회의 애플리케이션 또는 채팅 애플리케이션에서는 NLB를 사용하여 연결을 관리하는 것이 조금 더 적합합니다. NLB를 사용하므로써 세션 지속성을 효과적으로 유지할 수 있습니다.

> L4, L7은 각각 Layer 4(전송 계층) 프로토콜과 Layer 7(응용 계층) `프로토콜의 헤더를 부하 분산에 이용하기 때문에 붙은 접두사이다.` 

### 3. ELB(Elastic Load Balancer)
Elastic Load Balancer (ELB)는 Amazon Web Services (AWS)에서 제공하는 클라우드 기반 로드 밸런서 서비스입니다. ELB는 들어오는 트래픽을 여러 EC2 인스턴스 또는 다른 백엔드 서비스로 분산시켜 시스템의 가용성과 성능을 향상시키는 역할을 합니다. ELB는 트래픽의 분산, 서버의 상태 검사, 자동 스케일링과 같은 다양한 기능을 제공합니다.
### 4. GSLB (Global Server Load Balancing)

글로벌 서버 로드 밸런싱은 전 세계의 여러 지역에 분포된 서버 간에 트래픽을 분산시키는 것을 말합니다. 이는 사용자들에게 지역적으로 가장 가까운 서버로부터 서비스를 받을 수 있도록 도와주며, 네트워크 지연을 최소화하여 응답 시간을 개선합니다.

### 5. DNS LB (DNS Load Balancing)

DNS 로드 밸런싱은 DNS(Domain Name System) 서버를 사용하여 클라이언트의 DNS 쿼리를 처리하고, 여러 서버 중 하나의 IP 주소로 응답하는 방법입니다. 이를 통해 클라이언트는 여러 서버 중 하나를 선택하여 요청을 보낼 수 있습니다.
### 사진
![[Pasted image 20240119050905.png]]
![[Pasted image 20240119051620.png]]
## 로드 밸런싱 알고리즘

로드 밸런싱 기법은 여러 가지가 있다. 서버의 능력을 고려하여 분배해야 하기 때문에 서버의 상황에 맞춰 적절한 방법을 선택해야 합니다다. 로드 밸런싱 알고리즘은 크게 2가지 범주로 나뉩니다.
### 정적 로드 밸런싱

정적 로드 밸런싱 알고리즘은 고정된 규칙을 따르며 현재 서버 상태와 무관합니다. 다음은 정적 로드 밸런싱의 예제입니다.
#### 라운드로빈 방식(Round Robin Method)
    
서버에 들어온 요청을 순서대로 돌아가며 배정하는 방식이다. 클라이언트의 요청을 순서대로 분배하기 때문에 여러 대의 서버가 동일한 스펙을 갖고 있고, 서버와의 연결(세션)이 오래 지속되지 않는 경우에 활용하기 적합하다.

#### 가중 라운드로빈 방식(Weighted Round Robin Method)

각각의 서버마다 가중치를 매기고 가중치가 높은 서버에 클라이언트 요청을 우선적으로 배분한다. 주로 서버의 트래픽 처리 능력이 상이한 경우 사용되는 부하 분산 방식이다. 예를 들어 A라는 서버가 5라는 가중치를 갖고 B라는 서버가 2라는 가중치를 갖는다면, 로드 밸런서는 라운드로빈 방식으로 A 서버에 5개 B 서버에 2개의 요청을 전달한다.

#### IP 해시 방식(IP Hash Method)
    
클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리하는 방식이다. 사용자의 IP를 해싱해(Hashing, 임의의 길이를 지닌 데이터를 고정된 길이의 데이터로 매핑하는 것, 또는 그러한 함수) 로드를 분배하기 때문에 사용자가 항상 동일한 서버로 연결되는 것을 보장한다.

### 동적 로드 밸런싱 

동적 로드 밸런싱 알고리즘은 트래픽을 배포하기 전에 서버의 현재 상태를 검사합니다. 다음은 동적 로드 밸런싱 알고리즘의 몇 가지 예제입니다.

#### 최소 연결 방식(Least Connection Method)
    
요청이 들어온 시점에 가장 적은 연결상태를 보이는 서버에 우선적으로 트래픽을 배분한다. 자주 세션이 길어지거나, 서버에 분배된 트래픽들이 일정하지 않은 경우에 적합한 방식이다. 이 방법에서는 모든 연결에 모든 서버에 대해 동일한 처리 능력이 필요하다고 가정합니다.



#### 가중치 기반 최소 연결 방법(Weighted Least Connections)

가중치 기반 최소 연결 방법은 서버에 가중치를 할당하고, 현재 연결 상태가 가장 적은 서버에 트래픽을 분배하는 로드 밸런싱 알고리즘입니다. 이 방법은 서버 간의 성능이나 용량 차이를 고려하여 효율적으로 트래픽을 분산하는 데 사용됩니다.
#### 최소 응답 시간 방식(Least Response Time Method)
    
서버의 현재 연결 상태와 응답 시간(Response Time, 서버에 요청을 보내고 최초 응답을 받을 때까지 소요되는 시간)을 모두 고려하여 트래픽을 배분한다. 가장 적은 연결 상태와 가장 짧은 응답 시간을 보이는 서버에 우선적으로 로드를 배분하는 방식이다.

#### **리소스 기반 방법(Resource-Based Method)**
서버의 리소스 사용량을 고려하여 트래픽을 분배하는 방식입니다. 예를 들어, CPU 사용률, 메모리 사용량 등과 같은 서버 리소스를 측정하여 현재 부하 상태를 파악하고, 가장 낮은 부하를 가진 서버에 트래픽을 분배합니다. 이는 서버 간 성능 차이를 고려하여 효과적으로 로드를 분산할 수 있습니다.
